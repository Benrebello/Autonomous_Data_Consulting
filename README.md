# Autonomous Data Consulting

Sistema multi-agente de IA para anÃ¡lise exploratÃ³ria de dados (EDA) autÃ´noma. FaÃ§a upload de datasets e interaja com uma equipe de agentes especializados para extrair insights, gerar visualizaÃ§Ãµes e obter conclusÃµes acionÃ¡veis.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Tests](https://img.shields.io/badge/tests-23%2F23%20passing-success.svg)](./tests/)
[![Code Style](https://img.shields.io/badge/code%20style-modular-brightgreen.svg)](./tools/)

[ðŸ‡§ðŸ‡· VersÃ£o em PortuguÃªs](#Ã­ndice) | [ðŸ‡ºðŸ‡¸ English Version](#english-version)

---

## Ãndice

- [Sobre](#sobre)
- [Funcionalidades](#funcionalidades)
- [Arquitetura](#arquitetura)
  - [Pacote de Ferramentas Modular](#pacote-de-ferramentas-modular)
  - [Sistema de Agentes](#sistema-de-agentes)
  - [Pipeline de ExecuÃ§Ã£o](#pipeline-de-execuÃ§Ã£o)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso](#uso)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [DocumentaÃ§Ã£o](#documentaÃ§Ã£o)
- [Testes](#testes)
- [Contribuindo](#contribuindo)
- [LicenÃ§a](#licenÃ§a)

## Sobre

Sistema multi-agente de IA para anÃ¡lise exploratÃ³ria de dados (EDA) autÃ´noma. FaÃ§a upload de datasets e interaja com uma equipe de agentes especializados para extrair insights, gerar visualizaÃ§Ãµes e obter conclusÃµes acionÃ¡veis.

## Funcionalidades

### Capacidades Core
- **ðŸ¤– OrquestraÃ§Ã£o Multi-Agente**: 6 agentes especializados trabalhando colaborativamente
- **ðŸ“Š 211 FunÃ§Ãµes de AnÃ¡lise**: Toolkit abrangente organizado em 21 mÃ³dulos especializados (125 exportadas)
- **ðŸ“ˆ Analytics AvanÃ§ado**: Testes estatÃ­sticos, modelos ML, sÃ©ries temporais, mÃ©tricas de negÃ³cio
- **ðŸ’° Analytics Financeiro**: NPV, TIR, volatilidade, precificaÃ§Ã£o Black-Scholes
- **ðŸ”¢ OperaÃ§Ãµes MatemÃ¡ticas**: CÃ¡lculo, Ã¡lgebra linear, otimizaÃ§Ã£o
- **ðŸ“ CÃ¡lculos GeomÃ©tricos**: MÃ©tricas de distÃ¢ncia, Ã¡rea de polÃ­gonos
- **ðŸŽ¨ VisualizaÃ§Ãµes Ricas**: 7 tipos de grÃ¡ficos com renderizaÃ§Ã£o em memÃ³ria
- **ðŸ“„ Suporte Multi-Formato**: CSV, XLSX, XLS, ODS, ODT (extraÃ§Ã£o de tabelas)
- **ðŸ”— JunÃ§Ã£o Inteligente**: DetecÃ§Ã£o automÃ¡tica de chaves e configuraÃ§Ã£o de joins
- **ðŸ“± UI Interativa**: Chat em tempo real, acompanhamento de progresso, relatÃ³rios PDF

### Recursos AvanÃ§ados
- **ðŸŽ¯ DetecÃ§Ã£o de IntenÃ§Ã£o via LLM**: Sistema inteligente com 8 modelos predefinidos de intenÃ§Ã£o
- **ðŸ”§ Tool Registry 100%**: 93 ferramentas registradas com descoberta dinÃ¢mica e validaÃ§Ã£o automÃ¡tica
- **ðŸ” Busca Inteligente**: NormalizaÃ§Ã£o de acentos, ordenaÃ§Ã£o por especificidade, validaÃ§Ã£o de compatibilidade
- **ðŸ’¡ RecomendaÃ§Ãµes IA**: Sistema de scoring que sugere ferramentas baseado em caracterÃ­sticas do DataFrame
- **âœ… ValidaÃ§Ã£o Preventiva**: Verifica requisitos antes de executar (min rows, colunas numÃ©ricas, etc.)
- **ðŸ“Š SugestÃµes Contextuais**: AnÃ¡lises recomendadas dinamicamente baseadas no dataset
- **ðŸ”„ Discovery Conversacional**: Faz perguntas inteligentes apenas quando necessÃ¡rio
- **Gerenciamento de Estado Tipado**: AppState com sincronizaÃ§Ã£o bidirecional
- **Rate Limiting**: Controle de RPM com feedback visual
- **ExecuÃ§Ã£o Paralela**: ParalelizaÃ§Ã£o de tarefas independentes
- **Sistema de Cache Inteligente**: Cache baseado em query + intent + response_mode (TTL 5min direto, 1h completo)
- **RevisÃ£o QA**: AnÃ¡lise crÃ­tica dos resultados antes da resposta final
- **MÃ©tricas & Analytics**: Taxas de sucesso, tempos de execuÃ§Ã£o
- **ExportaÃ§Ã£o PDF**: RelatÃ³rios formatados ABNT com estrutura PirÃ¢mide de Minto
- **IntegraÃ§Ã£o Nativa de Conectores**: Suporte a queries federadas SQL
- **Modo de Resposta Adaptativo**: DetecÃ§Ã£o automÃ¡tica de intenÃ§Ã£o (direto vs completo)
- **Tratamento de Erros Robusto**: Stack traces completos para debugging

## Arquitetura

### Pacote de Ferramentas Modular

O sistema possui um pacote `tools/` totalmente modular com 21 mÃ³dulos especializados:

```
tools/
â”œâ”€â”€ data_profiling.py          # 17 funÃ§Ãµes: estatÃ­sticas, tipos, cardinalidade
â”œâ”€â”€ statistical_tests.py       # 14 funÃ§Ãµes: teste t, ANOVA, MANOVA, sobrevivÃªncia
â”œâ”€â”€ correlation_analysis.py    # 6 funÃ§Ãµes: correlaÃ§Ã£o, VIF, relacionamentos
â”œâ”€â”€ outlier_detection.py       # 5 funÃ§Ãµes: detecÃ§Ã£o IQR, Z-score
â”œâ”€â”€ visualization.py           # 11 funÃ§Ãµes: grÃ¡ficos, plots, heatmaps
â”œâ”€â”€ machine_learning.py        # 42 funÃ§Ãµes: regressÃ£o, classificaÃ§Ã£o, tuning, AutoML
â”œâ”€â”€ clustering.py              # 6 funÃ§Ãµes: K-means, anÃ¡lise de clusters
â”œâ”€â”€ time_series.py             # 8 funÃ§Ãµes: decomposiÃ§Ã£o, ARIMA, features
â”œâ”€â”€ feature_engineering.py     # 6 funÃ§Ãµes: polinomiais, interaÃ§Ãµes, binning
â”œâ”€â”€ business_analytics.py      # 9 funÃ§Ãµes: RFM, taxa de crescimento, teste A/B, cohort
â”œâ”€â”€ advanced_analytics.py      # 12 funÃ§Ãµes: previsÃ£o, risco, simulaÃ§Ã£o
â”œâ”€â”€ text_analysis.py           # 7 funÃ§Ãµes: sentimento, tÃ³picos, wordcloud, NER
â”œâ”€â”€ geospatial.py              # 3 funÃ§Ãµes: mapeamento geogrÃ¡fico
â”œâ”€â”€ data_transformation.py     # 13 funÃ§Ãµes: joins, pivots, normalizaÃ§Ã£o
â”œâ”€â”€ data_cleaning.py           # 7 funÃ§Ãµes: validaÃ§Ã£o, imputaÃ§Ã£o
â”œâ”€â”€ file_operations.py         # 10 funÃ§Ãµes: ODT, exportaÃ§Ã£o Excel, conectores
â”œâ”€â”€ math_operations.py         # 8 funÃ§Ãµes: aritmÃ©tica, cÃ¡lculo
â”œâ”€â”€ financial_analytics.py     # 6 funÃ§Ãµes: NPV, TIR, Black-Scholes
â”œâ”€â”€ advanced_math.py           # 7 funÃ§Ãµes: sistemas lineares, otimizaÃ§Ã£o
â”œâ”€â”€ geometry.py                # 5 funÃ§Ãµes: distÃ¢ncias, Ã¡rea de polÃ­gonos
â””â”€â”€ helpers.py                 # 9 funÃ§Ãµes: utilitÃ¡rios internos
```

### Sistema de Agentes

**10 Agentes Especializados com IA Adaptativa:**

#### **Agentes Core (6):**
1. **OrchestratorAgent**: Traduz consultas em linguagem natural para briefings estruturados com detecÃ§Ã£o de intenÃ§Ã£o
2. **TeamLeaderAgent**: Cria planos de execuÃ§Ã£o e sintetiza resultados
3. **DataArchitectAgent**: Limpeza, junÃ§Ã£o e preparaÃ§Ã£o de dados
4. **DataAnalystTechnicalAgent**: AnÃ¡lise estatÃ­stica e EDA profunda
5. **DataAnalystBusinessAgent**: VisualizaÃ§Ãµes e insights de negÃ³cio
6. **DataScientistAgent**: Machine learning e modelagem preditiva

#### **Agentes Especializados por DomÃ­nio (4):**
7. **FinancialAgent**: AnÃ¡lise financeira especializada (NPV, TIR, volatilidade, Black-Scholes)
8. **MarketingAgent**: Analytics de marketing (RFM, CAC, LTV, segmentaÃ§Ã£o de clientes)
9. **OperationalAgent**: EficiÃªncia operacional (produtividade, gargalos, KPIs operacionais)
10. **DataIntegrationAgent**: IntegraÃ§Ã£o de dados federados (conectores SQL, queries distribuÃ­das)

#### **Modo de Resposta Dual:**
- **Modo Direto**: Para perguntas simples â†’ Respostas concisas e focadas
- **Modo Completo**: Para anÃ¡lises profundas â†’ RelatÃ³rios abrangentes com PDF

### Pipeline de ExecuÃ§Ã£o

```mermaid
flowchart LR
    A[Consulta do UsuÃ¡rio] --> B[Orchestrator: Briefing]
    B --> C[Team Leader: Plano]
    C --> D[Agentes: Executar Tarefas]
    D --> E[Team Leader: SÃ­ntese]
    E --> F[RevisÃ£o QA]
    F --> G[Resposta Final]
    G --> H[ExportaÃ§Ã£o PDF]
```

## InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- Chave de API LLM (Groq, OpenAI ou Google Gemini)

### Passos

1. **Clone o repositÃ³rio:**
   ```bash
   git clone https://github.com/Benrebello/Autonomous_Data_Consulting
   cd Autonomous_Data_Consulting
   ```

2. **Instale as dependÃªncias:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure o LLM em `config.json`:**
   ```json
   {
     "provider": "groq",
     "model": "llama-3.1-8b-instant",
     "api_key": "sua-chave-api-aqui"
   }
   ```

4. **Execute a aplicaÃ§Ã£o:**
   ```bash
   streamlit run app.py
   ```

## Uso

1. **FaÃ§a upload de datasets** (CSV, XLSX, XLS, ODS, ODT) via barra lateral
2. **Configure as definiÃ§Ãµes:**
   - Habilite normalizaÃ§Ã£o de colunas (snake_case)
   - Selecione DataFrame padrÃ£o
   - Configure relacionamentos entre datasets e chaves de junÃ§Ã£o
3. **FaÃ§a perguntas** em linguagem natural:
   - "FaÃ§a uma EDA completa do dataset"
   - "Detecte outliers na coluna 'preÃ§o'"
   - "Qual a correlaÃ§Ã£o entre 'vendas' e 'publicidade'?"
   - "Execute clustering K-means com 3 clusters"
4. **Revise os resultados:**
   - Plano de execuÃ§Ã£o com dependÃªncias de tarefas
   - Acompanhamento de progresso
   - VisualizaÃ§Ãµes interativas
   - RelatÃ³rio de anÃ¡lise abrangente
5. **Exporte:** Baixe relatÃ³rio PDF com descobertas

## Estrutura do Projeto

```
Autonomous_Data_Consulting/
â”œâ”€â”€ app.py                      # AplicaÃ§Ã£o principal Streamlit
â”œâ”€â”€ agents.py                   # DefiniÃ§Ãµes de agentes
â”œâ”€â”€ config.py                   # ConfiguraÃ§Ã£o LLM
â”œâ”€â”€ state.py                    # Gerenciamento de estado tipado
â”œâ”€â”€ prompts.py                  # Templates de prompts
â”œâ”€â”€ prompt_templates.py         # GeraÃ§Ã£o dinÃ¢mica de prompts
â”œâ”€â”€ rate_limiter.py             # LimitaÃ§Ã£o de RPM
â”œâ”€â”€ ui_components.py            # UtilitÃ¡rios de UI
â”œâ”€â”€ optimizations.py            # OtimizaÃ§Ãµes de performance
â”œâ”€â”€ tool_registry.py            # Metadados e registro de ferramentas
â”œâ”€â”€ tools/                      # Pacote de ferramentas modular (21 mÃ³dulos)
â”‚   â”œâ”€â”€ __init__.py            # 125 exportaÃ§Ãµes de funÃ§Ãµes
â”‚   â”œâ”€â”€ data_profiling.py
â”‚   â”œâ”€â”€ statistical_tests.py
â”‚   â”œâ”€â”€ machine_learning.py
â”‚   â”œâ”€â”€ advanced_analytics.py
â”‚   â”œâ”€â”€ financial_analytics.py
â”‚   â”œâ”€â”€ math_operations.py
â”‚   â”œâ”€â”€ geometry.py
â”‚   â””â”€â”€ ... (14 mÃ³dulos adicionais)
â”œâ”€â”€ tests/                      # Suite de testes (23 testes)
â”‚   â”œâ”€â”€ test_clustering.py
â”‚   â”œâ”€â”€ test_business_analytics.py
â”‚   â”œâ”€â”€ test_tools_mapping.py
â”‚   â””â”€â”€ ... (10 arquivos de teste adicionais)
â”œâ”€â”€ docs/                       # DocumentaÃ§Ã£o abrangente
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ OPERATIONS.md
â”‚   â”œâ”€â”€ TESTING.md
â”‚   â””â”€â”€ ... (11 documentos adicionais)
â”œâ”€â”€ config.json                 # ConfiguraÃ§Ã£o LLM
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â””â”€â”€ README.md                   # Este arquivo
```

## DocumentaÃ§Ã£o

### DocumentaÃ§Ã£o Core
- **[ARCHITECTURE.md](./docs/ARCHITECTURE.md)**: Arquitetura do sistema e decisÃµes de design
- **[OPERATIONS.md](./docs/OPERATIONS.md)**: Guia de deployment e operaÃ§Ãµes
- **[TESTING.md](./docs/TESTING.md)**: EstratÃ©gia de testes e cobertura
- **[TROUBLESHOOTING.md](./docs/TROUBLESHOOTING.md)**: Problemas comuns e soluÃ§Ãµes

### DocumentaÃ§Ã£o TÃ©cnica
- **[RATE_LIMITING.md](./docs/RATE_LIMITING.md)**: ImplementaÃ§Ã£o de rate limiting
- **[CACHE.md](./docs/CACHE.md)**: EstratÃ©gia de cache de planos
- **[ANALYTICS.md](./docs/ANALYTICS.md)**: MÃ©tricas e analytics
- **[SECURITY.md](./docs/SECURITY.md)**: ConsideraÃ§Ãµes de seguranÃ§a
- **[TOOLS_ANALYSIS.md](./docs/TOOLS_ANALYSIS.md)**: ReferÃªncia completa de ferramentas

### Contribuindo
- **[CONTRIBUTING.md](./CONTRIBUTING.md)**: Diretrizes de contribuiÃ§Ã£o
- **[CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md)**: PadrÃµes da comunidade
- **[CHANGELOG.md](./CHANGELOG.md)**: HistÃ³rico de versÃµes

## Testes

O projeto inclui uma suite de testes abrangente com 100% de taxa de aprovaÃ§Ã£o:

```bash
pytest -q
# 23 passed, 17 warnings in 14.38s
```

**Cobertura de Testes:**
- âœ… Algoritmos de clustering
- âœ… Engenharia de features
- âœ… Analytics de negÃ³cio
- âœ… AnÃ¡lise de sÃ©ries temporais
- âœ… AnÃ¡lise de texto
- âœ… TransformaÃ§Ã£o de dados
- âœ… OperaÃ§Ãµes de arquivo
- âœ… ValidaÃ§Ã£o completa de mapeamento de ferramentas

## Estrutura de Ferramentas

**21 mÃ³dulos especializados com 211 funÃ§Ãµes:**

| MÃ³dulo | FunÃ§Ãµes | DescriÃ§Ã£o |
|--------|---------|-----------|
| data_profiling | 17 | EstatÃ­sticas, tipos, cardinalidade |
| statistical_tests | 14 | Testes t, ANOVA, MANOVA, sobrevivÃªncia |
| machine_learning | 42 | RegressÃ£o, classificaÃ§Ã£o, tuning, AutoML |
| advanced_analytics | 12 | PrevisÃ£o, risco, simulaÃ§Ã£o Monte Carlo |
| financial_analytics | 6 | NPV, TIR, Black-Scholes |
| math_operations | 8 | AritmÃ©tica, derivadas, integrais |
| advanced_math | 7 | Sistemas lineares, otimizaÃ§Ã£o |
| geometry | 5 | DistÃ¢ncias, Ã¡rea de polÃ­gonos |
| feature_engineering | 6 | Polinomiais, interaÃ§Ãµes, binning |
| business_analytics | 9 | RFM, taxa de crescimento, teste A/B, cohort |
| time_series | 8 | DecomposiÃ§Ã£o, ARIMA |
| text_analysis | 7 | Sentimento, tÃ³picos, wordcloud, NER |
| visualization | 11 | Histogramas, scatter, heatmaps |
| clustering | 6 | K-means, anÃ¡lise de clusters |
| correlation_analysis | 6 | CorrelaÃ§Ã£o, VIF, relaÃ§Ãµes |
| outlier_detection | 5 | IQR, Z-score |
| data_transformation | 13 | Joins, pivots, normalizaÃ§Ã£o |
| data_cleaning | 7 | ValidaÃ§Ã£o, imputaÃ§Ã£o |
| file_operations | 10 | ODT, exportaÃ§Ã£o Excel, conectores |
| geospatial | 3 | Mapas geogrÃ¡ficos |
| helpers | 9 | UtilitÃ¡rios internos |

## Exemplos de Uso

```python
# Exemplos de perguntas (em portuguÃªs para a UI)

# Perguntas Diretas (modo rÃ¡pido)
"Quais sÃ£o as medidas de tendÃªncia central (mÃ©dia, mediana)?"
"Quanto Ã© o total de vendas?"
"Qual a correlaÃ§Ã£o entre preÃ§o e quantidade?"

# AnÃ¡lises Financeiras (FinancialAgent)
"Calcule o NPV com taxa de 10% para os fluxos de caixa"
"Avalie o risco de volatilidade desta carteira"
"Qual a TIR deste investimento?"

# Analytics de Marketing (MarketingAgent)  
"FaÃ§a anÃ¡lise RFM dos clientes"
"Qual o CAC por canal de marketing?"
"Avalie a retenÃ§Ã£o de clientes por segmento"

# EficiÃªncia Operacional (OperationalAgent)
"Quais sÃ£o os gargalos no processo?"
"Avalie a produtividade por departamento"
"Identifique oportunidades de melhoria operacional"

# IntegraÃ§Ã£o de Dados (DataIntegrationAgent)
"Conecte ao banco de dados SQL e execute esta query"
"Junte dados de mÃºltiplas fontes externas"
"Monitore a qualidade dos dados federados"

# AnÃ¡lises Complexas (modo completo)
"FaÃ§a uma EDA completa do dataset"
"Execute anÃ¡lise preditiva com machine learning"
"Avalie tendÃªncias e padrÃµes temporais"
```

## Tecnologias Principais

- **Frontend**: Streamlit
- **Processamento de Dados**: pandas, numpy
- **ML/Stats**: scikit-learn, scipy, statsmodels
- **VisualizaÃ§Ã£o**: matplotlib, seaborn
- **IntegraÃ§Ã£o LLM**: langchain (Groq, OpenAI, Gemini)
- **Formatos de Arquivo**: openpyxl, odfpy, xlrd
- **GeraÃ§Ã£o PDF**: reportlab
- **ValidaÃ§Ã£o**: pydantic

## Performance

- **ExecuÃ§Ã£o Paralela**: Tarefas independentes executam concorrentemente
- **Cache Inteligente**: Sistema dual com TTL adaptativo (5min respostas diretas, 1h anÃ¡lises completas)
- **CompressÃ£o de Contexto**: Resultados grandes sÃ£o automaticamente resumidos
- **Rate Limiting**: Previne throttling de API
- **Lazy Loading**: Ferramentas carregadas sob demanda
- **DetecÃ§Ã£o de IntenÃ§Ã£o**: Processamento adaptativo baseado na complexidade da query

## Roadmap

### âœ… Implementado (v1.0)
- [x] Sistema de cache inteligente com TTL duplo
- [x] Agentes especializados por domÃ­nio (Financeiro, Marketing, Operacional, IntegraÃ§Ã£o)
- [x] Modo de resposta dual (direto vs completo)
- [x] IntegraÃ§Ã£o nativa de conectores SQL
- [x] DetecÃ§Ã£o automÃ¡tica de intenÃ§Ã£o conversacional
- [x] **Tool Registry 100%**: Descoberta dinÃ¢mica, validaÃ§Ã£o, recomendaÃ§Ãµes IA
- [x] **Sistema de IntenÃ§Ã£o via LLM**: 8 modelos predefinidos com contexto do DataFrame
- [x] **NormalizaÃ§Ã£o de texto**: Busca funciona com/sem acentos
- [x] **ValidaÃ§Ã£o preventiva**: Feedback claro antes de executar ferramentas
- [x] **SugestÃµes inteligentes**: RecomendaÃ§Ãµes baseadas em scoring contextual
- [x] **Tratamento de erros**: Stack traces completos para debugging

### ðŸ”„ Em Desenvolvimento (v1.1)
- [ ] Implementar versionamento de dados
- [ ] Criar endpoint REST API
- [ ] Adicionar suporte a dados em streaming em tempo real
- [ ] Implementar recursos colaborativos
- [ ] Adicionar mais modelos ML (CatBoost, Neural Networks)
- [ ] Sistema de feedback do usuÃ¡rio para melhorar recomendaÃ§Ãµes

## Contribuindo

1. FaÃ§a fork do repositÃ³rio
2. Crie uma branch de feature (`git checkout -b feature/nova-ferramenta`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova ferramenta de anÃ¡lise'`)
4. Push para a branch (`git push origin feature/nova-ferramenta`)
5. Abra um Pull Request

Veja [CONTRIBUTING.md](./CONTRIBUTING.md) para diretrizes detalhadas.

## Suporte

Para problemas, questÃµes ou sugestÃµes:
- Abra uma issue no GitHub
- Consulte [TROUBLESHOOTING.md](./docs/TROUBLESHOOTING.md)
- Revise a [documentaÃ§Ã£o](./docs/)

## LicenÃ§a

Este projeto faz parte do desafio individual I2A2.

## Autor

Desenvolvido por [Ben Rebello](https://github.com/Benrebello)

## Agradecimentos

- ConstruÃ­do com LangChain para orquestraÃ§Ã£o LLM
- Streamlit para UI interativa
- scikit-learn para capacidades ML
- pandas para manipulaÃ§Ã£o de dados

---

# English Version

## Table of Contents

- [Features](#features-1)
- [Architecture](#architecture-1)
  - [Modular Tools Package](#modular-tools-package-1)
  - [Agent System](#agent-system-1)
  - [Execution Pipeline](#execution-pipeline-1)
- [Installation](#installation-1)
- [Usage](#usage-1)
- [Project Structure](#project-structure-1)
- [Documentation](#documentation-1)
- [Testing](#testing-1)
- [Contributing](#contributing-1)
- [License](#license-1)

## About

A multi-agent AI system for autonomous exploratory data analysis (EDA). Upload datasets and interact with a team of specialized AI agents to extract insights, generate visualizations, and obtain actionable conclusions.

## Features

### Core Capabilities
- **ðŸ¤– Multi-Agent Orchestration**: 10 specialized AI agents working collaboratively with adaptive intelligence
- **ðŸ“Š 211 Analysis Functions**: Comprehensive toolkit organized in 21 specialized modules (125 exported)
- **ðŸ“ˆ Advanced Analytics**: Statistical tests, ML models, time series, business metrics
- **ðŸ’° Financial Analytics**: NPV, IRR, volatility, Black-Scholes option pricing
- **ðŸ”¢ Mathematical Operations**: Calculus, linear algebra, optimization
- **ðŸ“ Geometric Calculations**: Distance metrics, polygon area
- **ðŸŽ¨ Rich Visualizations**: 7 chart types with in-memory rendering
- **ðŸ“„ Multi-Format Support**: CSV, XLSX, XLS, ODS, ODT (table extraction)
- **ðŸ”— Smart Dataset Joining**: Automatic key detection and join configuration
- **ðŸ“± Interactive UI**: Real-time chat, progress tracking, PDF reports

### Advanced Features
- **ðŸŽ¯ LLM-Based Intent Detection**: Intelligent system with 8 predefined intent models
- **ðŸ”§ 100% Tool Registry**: 93 registered tools with dynamic discovery and automatic validation
- **ðŸ” Smart Search**: Accent normalization, specificity ordering, compatibility validation
- **ðŸ’¡ AI Recommendations**: Scoring system that suggests tools based on DataFrame characteristics
- **âœ… Preventive Validation**: Checks requirements before execution (min rows, numeric columns, etc.)
- **ðŸ“Š Contextual Suggestions**: Dynamically recommended analyses based on dataset
- **ðŸ”„ Conversational Discovery**: Asks intelligent questions only when necessary
- **Typed State Management**: AppState with bidirectional sync
- **Rate Limiting**: RPM control with visual feedback
- **Parallel Execution**: Independent task parallelization
- **Smart Cache System**: Query + intent + response_mode based cache (5min direct, 1h complete TTL)
- **QA Review**: Critical analysis of results before final response
- **Metrics & Analytics**: Tool success rates, execution times
- **PDF Export**: ABNT-formatted reports with Minto Pyramid structure
- **Native SQL Connectors**: Federated query support across data sources
- **Adaptive Response Mode**: Automatic intent detection (direct vs complete mode)
- **Robust Error Handling**: Complete stack traces for debugging

## Architecture

### Modular Tools Package

The system features a fully modular `tools/` package with 21 specialized modules:

```
tools/
â”œâ”€â”€ data_profiling.py          # 17 functions: stats, types, cardinality
â”œâ”€â”€ statistical_tests.py       # 14 functions: t-test, ANOVA, MANOVA, survival
â”œâ”€â”€ correlation_analysis.py    # 6 functions: correlation, VIF, relationships
â”œâ”€â”€ outlier_detection.py       # 5 functions: IQR, Z-score detection
â”œâ”€â”€ visualization.py           # 11 functions: charts, plots, heatmaps
â”œâ”€â”€ machine_learning.py        # 42 functions: regression, classification, tuning, AutoML
â”œâ”€â”€ clustering.py              # 6 functions: K-means, cluster analysis
â”œâ”€â”€ time_series.py             # 8 functions: decomposition, ARIMA, features
â”œâ”€â”€ feature_engineering.py     # 6 functions: polynomial, interactions, binning
â”œâ”€â”€ business_analytics.py      # 9 functions: RFM, growth rate, A/B testing, cohort
â”œâ”€â”€ advanced_analytics.py      # 12 functions: forecasting, risk, simulation
â”œâ”€â”€ text_analysis.py           # 7 functions: sentiment, topics, wordcloud, NER
â”œâ”€â”€ geospatial.py              # 3 functions: geographic mapping
â”œâ”€â”€ data_transformation.py     # 13 functions: joins, pivots, normalization
â”œâ”€â”€ data_cleaning.py           # 7 functions: validation, imputation
â”œâ”€â”€ file_operations.py         # 10 functions: ODT, Excel export, connectors
â”œâ”€â”€ math_operations.py         # 8 functions: arithmetic, calculus
â”œâ”€â”€ financial_analytics.py     # 6 functions: NPV, IRR, Black-Scholes
â”œâ”€â”€ advanced_math.py           # 7 functions: linear systems, optimization
â”œâ”€â”€ geometry.py                # 5 functions: distances, polygon area
â””â”€â”€ helpers.py                 # 9 functions: internal utilities
```

### Agent System

**10 Specialized Agents with Adaptive AI:**

#### **Core Agents (6):**
1. **OrchestratorAgent**: Translates natural language queries into structured briefings with intent detection
2. **TeamLeaderAgent**: Creates execution plans and synthesizes results
3. **DataArchitectAgent**: Data cleaning, joining, and preparation
4. **DataAnalystTechnicalAgent**: Statistical analysis and deep EDA
5. **DataAnalystBusinessAgent**: Visualizations and business insights
6. **DataScientistAgent**: Machine learning and predictive modeling

#### **Domain-Specific Agents (4):**
7. **FinancialAgent**: Specialized financial analysis (NPV, IRR, volatility, Black-Scholes)
8. **MarketingAgent**: Marketing analytics (RFM, CAC, LTV, customer segmentation)
9. **OperationalAgent**: Operational efficiency (productivity, bottlenecks, operational KPIs)
10. **DataIntegrationAgent**: Federated data integration (SQL connectors, distributed queries)

#### **Dual Response Mode:**
- **Direct Mode**: For simple questions â†’ Concise, focused responses
- **Complete Mode**: For deep analysis â†’ Comprehensive reports with PDF

### Execution Pipeline

```mermaid
flowchart LR
    A[User Query] --> B[Orchestrator: Briefing]
    B --> C[Team Leader: Plan]
    C --> D[Agents: Execute Tasks]
    D --> E[Team Leader: Synthesis]
    E --> F[QA Review]
    F --> G[Final Response]
    G --> H[PDF Export]
```

## Installation

### Prerequisites
- Python 3.8+
- LLM API key (Groq, OpenAI, or Google Gemini)

### Steps

1. **Clone the repository:**
   ```bash
   git clone https://github.com/Benrebello/Autonomous_Data_Consulting
   cd Autonomous_Data_Consulting

   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure LLM in `config.json`:**
   ```json
   {
     "provider": "groq",
     "model": "llama-3.1-8b-instant",
     "api_key": "your-api-key-here"
   }
   ```

4. **Run the application:**
   ```bash
   streamlit run app.py
   ```

## Usage

1. **Upload datasets** (CSV, XLSX, XLS, ODS, ODT) via sidebar
2. **Configure settings:**
   - Enable column normalization (snake_case)
   - Select default DataFrame
   - Configure dataset relationships and join keys
3. **Ask questions** in natural language:
   - "What are the measures of central tendency (mean, median)?" *(Direct Mode)*
   - "Perform a complete EDA on the dataset" *(Complete Mode)*
   - "Calculate NPV with 10% rate for cash flows" *(Financial Agent)*
   - "Run RFM analysis on customers" *(Marketing Agent)*
   - "Identify operational bottlenecks" *(Operational Agent)*
   - "Connect to SQL database and run this query" *(Data Integration Agent)*
4. **Review results:**
   - Execution plan with task dependencies
   - Progress tracking
   - Interactive visualizations
   - Comprehensive analysis report
5. **Export:** Download PDF report with findings

## Project Structure

```
Autonomous_Data_Consulting/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ agents.py                   # Agent definitions
â”œâ”€â”€ config.py                   # LLM configuration
â”œâ”€â”€ state.py                    # Typed state management
â”œâ”€â”€ prompts.py                  # Prompt templates
â”œâ”€â”€ prompt_templates.py         # Dynamic prompt generation
â”œâ”€â”€ rate_limiter.py             # RPM rate limiting
â”œâ”€â”€ ui_components.py            # UI utilities
â”œâ”€â”€ optimizations.py            # Performance optimizations
â”œâ”€â”€ tool_registry.py            # Tool metadata and registry
â”œâ”€â”€ tools/                      # Modular tools package (21 modules)
â”‚   â”œâ”€â”€ __init__.py            # 125 function exports
â”‚   â”œâ”€â”€ data_profiling.py
â”‚   â”œâ”€â”€ statistical_tests.py
â”‚   â”œâ”€â”€ machine_learning.py
â”‚   â”œâ”€â”€ advanced_analytics.py
â”‚   â”œâ”€â”€ financial_analytics.py
â”‚   â”œâ”€â”€ math_operations.py
â”‚   â”œâ”€â”€ geometry.py
â”‚   â””â”€â”€ ... (14 more modules)
â”œâ”€â”€ tests/                      # Test suite (23 tests)
â”‚   â”œâ”€â”€ test_clustering.py
â”‚   â”œâ”€â”€ test_business_analytics.py
â”‚   â”œâ”€â”€ test_tools_mapping.py
â”‚   â””â”€â”€ ... (10 more test files)
â”œâ”€â”€ docs/                       # Comprehensive documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ OPERATIONS.md
â”‚   â”œâ”€â”€ TESTING.md
â”‚   â””â”€â”€ ... (11 more docs)
â”œâ”€â”€ config.json                 # LLM configuration
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

## Documentation

### Core Documentation
- **[ARCHITECTURE.md](./docs/ARCHITECTURE.md)**: System architecture and design decisions
- **[OPERATIONS.md](./docs/OPERATIONS.md)**: Deployment and operations guide
- **[TESTING.md](./docs/TESTING.md)**: Testing strategy and coverage
- **[TROUBLESHOOTING.md](./docs/TROUBLESHOOTING.md)**: Common issues and solutions

### Technical Documentation
- **[RATE_LIMITING.md](./docs/RATE_LIMITING.md)**: Rate limiting implementation
- **[CACHE.md](./docs/CACHE.md)**: Plan caching strategy
- **[ANALYTICS.md](./docs/ANALYTICS.md)**: Metrics and analytics
- **[SECURITY.md](./docs/SECURITY.md)**: Security considerations
- **[TOOLS_ANALYSIS.md](./docs/TOOLS_ANALYSIS.md)**: Complete tools reference

### Contributing
- **[CONTRIBUTING.md](./CONTRIBUTING.md)**: Contribution guidelines
- **[CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md)**: Community standards
- **[CHANGELOG.md](./CHANGELOG.md)**: Version history

## Testing

The project includes a comprehensive test suite with 100% pass rate:

```bash
pytest -q
# 23 passed, 17 warnings in 14.38s
```

**Test Coverage:**
- âœ… Clustering algorithms
- âœ… Feature engineering
- âœ… Business analytics
- âœ… Time series analysis
- âœ… Text analysis
- âœ… Data transformation
- âœ… File operations
- âœ… Complete tool mapping validation

## Key Technologies

- **Frontend**: Streamlit
- **Data Processing**: pandas, numpy
- **ML/Stats**: scikit-learn, scipy, statsmodels
- **Visualization**: matplotlib, seaborn
- **LLM Integration**: langchain (Groq, OpenAI, Gemini)
- **File Formats**: openpyxl, odfpy, xlrd
- **PDF Generation**: reportlab
- **Validation**: pydantic

## Performance

- **Parallel Execution**: Independent tasks run concurrently
- **Smart Cache System**: Dual TTL adaptive caching (5min direct responses, 1h complete analysis)
- **Context Compression**: Large results automatically summarized
- **Rate Limiting**: Prevents API throttling
- **Lazy Loading**: Tools loaded on demand
- **Intent Detection**: Adaptive processing based on query complexity

## Roadmap

### âœ… Implemented (v1.0)
- [x] Smart cache system with dual TTL
- [x] Domain-specific agents (Financial, Marketing, Operational, Integration)
- [x] Dual response mode (direct vs complete)
- [x] Native SQL connector integration
- [x] Automatic conversational intent detection
- [x] **100% Tool Registry**: Dynamic discovery, validation, AI recommendations
- [x] **LLM Intent System**: 8 predefined models with DataFrame context
- [x] **Text normalization**: Search works with/without accents
- [x] **Preventive validation**: Clear feedback before executing tools
- [x] **Smart suggestions**: Context-based scoring recommendations
- [x] **Error handling**: Complete stack traces for debugging

### ðŸ”„ In Development (v1.1)
- [ ] Implement data versioning
- [ ] Create REST API endpoint
- [ ] Add real-time streaming data support
- [ ] Implement collaborative features
- [ ] Add more ML models (CatBoost, Neural Networks)
- [ ] User feedback system to improve recommendations

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/new-tool`)
3. Commit your changes (`git commit -m 'Add new analysis tool'`)
4. Push to the branch (`git push origin feature/new-tool`)
5. Open a Pull Request

See [CONTRIBUTING.md](./CONTRIBUTING.md) for detailed guidelines.

## Support

For issues, questions, or suggestions:
- Open an issue on GitHub
- Check [TROUBLESHOOTING.md](./docs/TROUBLESHOOTING.md)
- Review [documentation](./docs/)

## License

This project is part of the I2A2 individual challenge.

## Author

Developed by [Ben Rebello](https://github.com/Benrebello)

## Acknowledgments

- Built with LangChain for LLM orchestration
- Streamlit for interactive UI
- scikit-learn for ML capabilities
- pandas for data manipulation

---
