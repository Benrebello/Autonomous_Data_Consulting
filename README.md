# Autonomous Data Consulting

A multi-agent AI system for autonomous exploratory data analysis (EDA). Upload datasets and interact with a team of specialized AI agents to extract insights, generate visualizations, and obtain actionable conclusions.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Tests](https://img.shields.io/badge/tests-23%2F23%20passing-success.svg)](./tests/)
[![Code Style](https://img.shields.io/badge/code%20style-modular-brightgreen.svg)](./tools/)

[üáßüá∑ Vers√£o em Portugu√™s](#vers√£o-em-portugu√™s) | [üá∫üá∏ English Version](#table-of-contents)

---

## Table of Contents

- [Features](#features)
- [Architecture](#architecture)
  - [Modular Tools Package](#modular-tools-package)
  - [Agent System](#agent-system)
  - [Execution Pipeline](#execution-pipeline)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Documentation](#documentation)
- [Testing](#testing)
- [Contributing](#contributing)
- [License](#license)

## Features

### Core Capabilities
- **ü§ñ Multi-Agent Orchestration**: 6 specialized AI agents working collaboratively
- **üìä 122 Analysis Tools**: Comprehensive toolkit organized in 21 specialized modules
- **üìà Advanced Analytics**: Statistical tests, ML models, time series, business metrics
- **üí∞ Financial Analytics**: NPV, IRR, volatility, Black-Scholes option pricing
- **üî¢ Mathematical Operations**: Calculus, linear algebra, optimization
- **üìê Geometric Calculations**: Distance metrics, polygon area
- **üé® Rich Visualizations**: 7 chart types with in-memory rendering
- **üìÑ Multi-Format Support**: CSV, XLSX, XLS, ODS, ODT (table extraction)
- **üîó Smart Dataset Joining**: Automatic key detection and join configuration
- **üì± Interactive UI**: Real-time chat, progress tracking, PDF reports

### Advanced Features
- **Dynamic Tool Registry**: 81 tools with automatic parameter defaults
- **Typed State Management**: AppState with bidirectional sync
- **Rate Limiting**: RPM control with visual feedback
- **Parallel Execution**: Independent task parallelization
- **Plan Caching**: Reuse successful execution plans
- **QA Review**: Critical analysis of results before final response
- **Metrics & Analytics**: Tool success rates, execution times
- **PDF Export**: ABNT-formatted reports with Minto Pyramid structure

## Architecture

### Modular Tools Package

The system features a fully modular `tools/` package with 21 specialized modules:

```
tools/
‚îú‚îÄ‚îÄ data_profiling.py          # 15 functions: stats, types, cardinality
‚îú‚îÄ‚îÄ statistical_tests.py       # 11 functions: t-test, ANOVA, MANOVA, survival
‚îú‚îÄ‚îÄ correlation_analysis.py    # 4 functions: correlation, VIF, relationships
‚îú‚îÄ‚îÄ outlier_detection.py       # 3 functions: IQR, Z-score detection
‚îú‚îÄ‚îÄ visualization.py           # 7 functions: charts, plots, heatmaps
‚îú‚îÄ‚îÄ machine_learning.py        # 15 functions: regression, classification, tuning
‚îú‚îÄ‚îÄ clustering.py              # 3 functions: K-means, cluster analysis
‚îú‚îÄ‚îÄ time_series.py             # 4 functions: decomposition, ARIMA, features
‚îú‚îÄ‚îÄ feature_engineering.py     # 5 functions: polynomial, interactions, binning
‚îú‚îÄ‚îÄ business_analytics.py      # 4 functions: RFM, growth rate, A/B testing
‚îú‚îÄ‚îÄ advanced_analytics.py      # 7 functions: forecasting, risk, simulation
‚îú‚îÄ‚îÄ text_analysis.py           # 3 functions: sentiment, topics, wordcloud
‚îú‚îÄ‚îÄ geospatial.py              # 1 function: geographic mapping
‚îú‚îÄ‚îÄ data_transformation.py     # 8 functions: joins, pivots, normalization
‚îú‚îÄ‚îÄ data_cleaning.py           # 6 functions: validation, imputation
‚îú‚îÄ‚îÄ file_operations.py         # 3 functions: ODT, Excel export
‚îú‚îÄ‚îÄ math_operations.py         # 7 functions: arithmetic, calculus
‚îú‚îÄ‚îÄ financial_analytics.py     # 5 functions: NPV, IRR, Black-Scholes
‚îú‚îÄ‚îÄ advanced_math.py           # 3 functions: linear systems, optimization
‚îú‚îÄ‚îÄ geometry.py                # 3 functions: distances, polygon area
‚îî‚îÄ‚îÄ helpers.py                 # 7 functions: internal utilities
```

### Agent System

**6 Specialized Agents:**

1. **OrchestratorAgent**: Translates natural language queries into structured briefings
2. **TeamLeaderAgent**: Creates execution plans and synthesizes results
3. **DataArchitectAgent**: Data cleaning, joining, and preparation
4. **DataAnalystTechnicalAgent**: Statistical analysis and deep EDA
5. **DataAnalystBusinessAgent**: Visualizations and business insights
6. **DataScientistAgent**: Machine learning and predictive modeling

### Execution Pipeline

```mermaid
flowchart LR
    A[User Query] --> B[Orchestrator: Briefing]
    B --> C[Team Leader: Plan]
    C --> D[Agents: Execute Tasks]
    D --> E[Team Leader: Synthesis]
    E --> F[QA Review]
    F --> G[Final Response]
    G --> H[PDF Export]
```

## Installation

### Prerequisites
- Python 3.8+
- LLM API key (Groq, OpenAI, or Google Gemini)

### Steps

1. **Clone the repository:**
   ```bash
   git clone https://github.com/Benrebello/Autonomous_Data_Consulting
   cd Autonomous_Data_Consulting

   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure LLM in `config.json`:**
   ```json
   {
     "provider": "groq",
     "model": "llama-3.1-8b-instant",
     "api_key": "your-api-key-here"
   }
   ```

4. **Run the application:**
   ```bash
   streamlit run app.py
   ```

## Usage

1. **Upload datasets** (CSV, XLSX, XLS, ODS, ODT) via sidebar
2. **Configure settings:**
   - Enable column normalization (snake_case)
   - Select default DataFrame
   - Configure dataset relationships and join keys
3. **Ask questions** in natural language:
   - "Perform a complete EDA on the dataset"
   - "Detect outliers in the 'price' column"
   - "What's the correlation between 'sales' and 'advertising'?"
   - "Run K-means clustering with 3 clusters"
4. **Review results:**
   - Execution plan with task dependencies
   - Progress tracking
   - Interactive visualizations
   - Comprehensive analysis report
5. **Export:** Download PDF report with findings

## Project Structure

```
Autonomous_Data_Consulting/
‚îú‚îÄ‚îÄ app.py                      # Main Streamlit application
‚îú‚îÄ‚îÄ agents.py                   # Agent definitions
‚îú‚îÄ‚îÄ config.py                   # LLM configuration
‚îú‚îÄ‚îÄ state.py                    # Typed state management
‚îú‚îÄ‚îÄ prompts.py                  # Prompt templates
‚îú‚îÄ‚îÄ prompt_templates.py         # Dynamic prompt generation
‚îú‚îÄ‚îÄ rate_limiter.py             # RPM rate limiting
‚îú‚îÄ‚îÄ ui_components.py            # UI utilities
‚îú‚îÄ‚îÄ optimizations.py            # Performance optimizations
‚îú‚îÄ‚îÄ tool_registry.py            # Tool metadata and registry
‚îú‚îÄ‚îÄ tools/                      # Modular tools package (21 modules)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # 122 function exports
‚îÇ   ‚îú‚îÄ‚îÄ data_profiling.py
‚îÇ   ‚îú‚îÄ‚îÄ statistical_tests.py
‚îÇ   ‚îú‚îÄ‚îÄ machine_learning.py
‚îÇ   ‚îú‚îÄ‚îÄ advanced_analytics.py
‚îÇ   ‚îú‚îÄ‚îÄ financial_analytics.py
‚îÇ   ‚îú‚îÄ‚îÄ math_operations.py
‚îÇ   ‚îú‚îÄ‚îÄ geometry.py
‚îÇ   ‚îî‚îÄ‚îÄ ... (14 more modules)
‚îú‚îÄ‚îÄ tests/                      # Test suite (23 tests)
‚îÇ   ‚îú‚îÄ‚îÄ test_clustering.py
‚îÇ   ‚îú‚îÄ‚îÄ test_business_analytics.py
‚îÇ   ‚îú‚îÄ‚îÄ test_tools_mapping.py
‚îÇ   ‚îî‚îÄ‚îÄ ... (10 more test files)
‚îú‚îÄ‚îÄ docs/                       # Comprehensive documentation
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md
‚îÇ   ‚îú‚îÄ‚îÄ OPERATIONS.md
‚îÇ   ‚îú‚îÄ‚îÄ TESTING.md
‚îÇ   ‚îî‚îÄ‚îÄ ... (11 more docs)
‚îú‚îÄ‚îÄ config.json                 # LLM configuration
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îî‚îÄ‚îÄ README.md                   # This file
```

## Documentation

### Core Documentation
- **[ARCHITECTURE.md](./docs/ARCHITECTURE.md)**: System architecture and design decisions
- **[OPERATIONS.md](./docs/OPERATIONS.md)**: Deployment and operations guide
- **[TESTING.md](./docs/TESTING.md)**: Testing strategy and coverage
- **[TROUBLESHOOTING.md](./docs/TROUBLESHOOTING.md)**: Common issues and solutions

### Technical Documentation
- **[RATE_LIMITING.md](./docs/RATE_LIMITING.md)**: Rate limiting implementation
- **[CACHE.md](./docs/CACHE.md)**: Plan caching strategy
- **[ANALYTICS.md](./docs/ANALYTICS.md)**: Metrics and analytics
- **[SECURITY.md](./docs/SECURITY.md)**: Security considerations
- **[TOOLS_ANALYSIS.md](./docs/TOOLS_ANALYSIS.md)**: Complete tools reference

### Contributing
- **[CONTRIBUTING.md](./CONTRIBUTING.md)**: Contribution guidelines
- **[CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md)**: Community standards
- **[CHANGELOG.md](./CHANGELOG.md)**: Version history

## Testing

The project includes a comprehensive test suite with 100% pass rate:

```bash
pytest -q
# 23 passed, 17 warnings in 14.38s
```

**Test Coverage:**
- ‚úÖ Clustering algorithms
- ‚úÖ Feature engineering
- ‚úÖ Business analytics
- ‚úÖ Time series analysis
- ‚úÖ Text analysis
- ‚úÖ Data transformation
- ‚úÖ File operations
- ‚úÖ Complete tool mapping validation

## Key Technologies

- **Frontend**: Streamlit
- **Data Processing**: pandas, numpy
- **ML/Stats**: scikit-learn, scipy, statsmodels
- **Visualization**: matplotlib, seaborn
- **LLM Integration**: langchain (Groq, OpenAI, Gemini)
- **File Formats**: openpyxl, odfpy, xlrd
- **PDF Generation**: reportlab
- **Validation**: pydantic

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/new-tool`)
3. Commit your changes (`git commit -m 'Add new analysis tool'`)
4. Push to the branch (`git push origin feature/new-tool`)
5. Open a Pull Request

See [CONTRIBUTING.md](./CONTRIBUTING.md) for detailed guidelines.

## License

This project is part of the I2A2 individual challenge.

## Author

Developed by [Ben Rebello](https://github.com/Benrebello)

---

# Vers√£o em Portugu√™s

## Sobre

Sistema multi-agente de IA para an√°lise explorat√≥ria de dados (EDA) aut√¥noma. Fa√ßa upload de datasets e interaja com uma equipe de agentes especializados para extrair insights, gerar visualiza√ß√µes e obter conclus√µes acion√°veis.

## Funcionalidades Principais

### Capacidades Core
- **ü§ñ Orquestra√ß√£o Multi-Agente**: 6 agentes especializados trabalhando colaborativamente
- **üìä 122 Ferramentas de An√°lise**: Toolkit abrangente organizado em 21 m√≥dulos especializados
- **üìà Analytics Avan√ßado**: Testes estat√≠sticos, modelos ML, s√©ries temporais, m√©tricas de neg√≥cio
- **üí∞ Analytics Financeiro**: NPV, TIR, volatilidade, precifica√ß√£o Black-Scholes
- **üî¢ Opera√ß√µes Matem√°ticas**: C√°lculo, √°lgebra linear, otimiza√ß√£o
- **üìê C√°lculos Geom√©tricos**: M√©tricas de dist√¢ncia, √°rea de pol√≠gonos
- **üé® Visualiza√ß√µes Ricas**: 7 tipos de gr√°ficos com renderiza√ß√£o em mem√≥ria
- **üìÑ Suporte Multi-Formato**: CSV, XLSX, XLS, ODS, ODT (extra√ß√£o de tabelas)
- **üîó Jun√ß√£o Inteligente**: Detec√ß√£o autom√°tica de chaves e configura√ß√£o de joins
- **üì± UI Interativa**: Chat em tempo real, acompanhamento de progresso, relat√≥rios PDF

### Recursos Avan√ßados
- **Registry Din√¢mico**: 81 ferramentas com defaults autom√°ticos de par√¢metros
- **Gerenciamento de Estado Tipado**: AppState com sincroniza√ß√£o bidirecional
- **Rate Limiting**: Controle de RPM com feedback visual
- **Execu√ß√£o Paralela**: Paraleliza√ß√£o de tarefas independentes
- **Cache de Planos**: Reutiliza√ß√£o de planos de execu√ß√£o bem-sucedidos
- **Revis√£o QA**: An√°lise cr√≠tica dos resultados antes da resposta final
- **M√©tricas & Analytics**: Taxas de sucesso, tempos de execu√ß√£o
- **Exporta√ß√£o PDF**: Relat√≥rios formatados ABNT com estrutura Pir√¢mide de Minto

## Instala√ß√£o

```bash
# Clone o reposit√≥rio
git clone https://github.com/Benrebello/Autonomous_Data_Consulting
cd Autonomous_Data_Consulting

# Instale as depend√™ncias
pip install -r requirements.txt

# Configure o LLM em config.json
# Execute a aplica√ß√£o
streamlit run app.py
```

## Estrutura de Ferramentas

**21 m√≥dulos especializados com 122 fun√ß√µes:**

| M√≥dulo | Fun√ß√µes | Descri√ß√£o |
|--------|---------|-----------|
| data_profiling | 15 | Estat√≠sticas, tipos, cardinalidade |
| statistical_tests | 11 | Testes t, ANOVA, MANOVA, sobreviv√™ncia |
| machine_learning | 15 | Regress√£o, classifica√ß√£o, tuning |
| advanced_analytics | 7 | Previs√£o, risco, simula√ß√£o Monte Carlo |
| financial_analytics | 5 | NPV, TIR, Black-Scholes |
| math_operations | 7 | Aritm√©tica, derivadas, integrais |
| advanced_math | 3 | Sistemas lineares, otimiza√ß√£o |
| geometry | 3 | Dist√¢ncias, √°rea de pol√≠gonos |
| feature_engineering | 5 | Polinomiais, intera√ß√µes, binning |
| business_analytics | 4 | RFM, taxa de crescimento, A/B test |
| time_series | 4 | Decomposi√ß√£o, ARIMA |
| text_analysis | 3 | Sentimento, t√≥picos, wordcloud |
| visualization | 7 | Histogramas, scatter, heatmaps |
| clustering | 3 | K-means, an√°lise de clusters |
| correlation_analysis | 4 | Correla√ß√£o, VIF, rela√ß√µes |
| outlier_detection | 3 | IQR, Z-score |
| data_transformation | 8 | Joins, pivots, normaliza√ß√£o |
| data_cleaning | 6 | Valida√ß√£o, imputa√ß√£o |
| file_operations | 3 | ODT, exporta√ß√£o Excel |
| geospatial | 1 | Mapas geogr√°ficos |
| helpers | 7 | Utilit√°rios internos |

## Sistema de Agentes

```mermaid
graph TD
    A[OrchestratorAgent] -->|Briefing| B[TeamLeaderAgent]
    B -->|Plan| C[DataArchitectAgent]
    B -->|Plan| D[DataAnalystTechnicalAgent]
    B -->|Plan| E[DataAnalystBusinessAgent]
    B -->|Plan| F[DataScientistAgent]
    C -->|Results| B
    D -->|Results| B
    E -->|Results| B
    F -->|Results| B
    B -->|Synthesis| G[QA Review]
    G -->|Final| H[User Response]
```

## Pipeline de Execu√ß√£o

1. **Briefing**: Orchestrator analisa a pergunta ‚Üí JSON estruturado
2. **Planning**: Team Leader cria plano de execu√ß√£o com depend√™ncias
3. **Execution**: Agentes executam tarefas em paralelo quando poss√≠vel
4. **Synthesis**: Team Leader sintetiza resultados
5. **QA Review**: Revis√£o cr√≠tica identifica limita√ß√µes
6. **Response**: Resposta final incorporando feedback QA
7. **Export**: Gera√ß√£o de relat√≥rio PDF

## Exemplos de Uso

```python
# Example questions (in Portuguese for UI)
"Fa√ßa uma EDA completa do dataset"
"Detecte outliers na coluna 'pre√ßo' usando IQR"
"Qual a correla√ß√£o entre 'vendas' e 'publicidade'?"
"Execute clustering K-means com 3 clusters"
"Calcule o NPV com taxa de 10% para os fluxos de caixa"
"Ajuste uma distribui√ß√£o normal aos dados de 'altura'"
```

## Testing

Run the complete test suite:

```bash
# All tests
pytest -q

# Specific module
pytest tests/test_clustering.py -v

# With coverage
pytest --cov=tools --cov-report=html
```

**Test Results:**
- 23/23 tests passing (100%)
- Coverage: Core modules fully tested
- Integration test validates all 81 registered tools

## Documentation

Comprehensive documentation available in `/docs`:

- **ARCHITECTURE.md**: System design and patterns
- **OPERATIONS.md**: Deployment guide
- **TESTING.md**: Test strategy
- **RATE_LIMITING.md**: RPM control implementation
- **CACHE.md**: Plan caching mechanism
- **ANALYTICS.md**: Metrics and logging
- **TOOLS_ANALYSIS.md**: Complete tool reference
- **SECURITY.md**: Security best practices
- **TROUBLESHOOTING.md**: Common issues

## Performance

- **Parallel Execution**: Independent tasks run concurrently
- **Smart Caching**: Successful plans cached by intent
- **Context Compression**: Large results automatically summarized
- **Rate Limiting**: Prevents API throttling
- **Lazy Loading**: Tools loaded on demand

## Roadmap

- [ ] Add more ML models (XGBoost, LightGBM)
- [ ] Implement data versioning
- [ ] Add SQL database connectors
- [ ] Create REST API endpoint
- [ ] Add real-time streaming data support
- [ ] Implement collaborative features

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for:
- Code style guidelines
- Testing requirements
- Pull request process
- Development setup

## Support

For issues, questions, or suggestions:
- Open an issue on GitHub
- Check [TROUBLESHOOTING.md](./docs/TROUBLESHOOTING.md)
- Review [documentation](./docs/)

## Acknowledgments

- Built with LangChain for LLM orchestration
- Streamlit for interactive UI
- scikit-learn for ML capabilities
- pandas for data manipulation

---

**Made with ‚ù§Ô∏è for the I2A2 Challenge**
