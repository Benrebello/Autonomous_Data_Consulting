# Autonomous Data Consulting

A multi-agent AI system for autonomous exploratory data analysis (EDA). Upload datasets and interact with a team of specialized AI agents to extract insights, generate visualizations, and obtain actionable conclusions.

[üáßüá∑ Vers√£o em Portugu√™s](#vers√£o-em-portugu√™s) | [üá∫üá∏ English Version](#english-version)

---

# English Version

## Sum√°rio

- [Funcionalidades](#funcionalidades)
- [Arquitetura](#arquitetura)
  - [Ferramentas](#ferramentas)
  - [Documenta√ß√£o](#documenta√ß√£o)
  - [Pipeline de Execu√ß√£o](#pipeline-de-execu√ß√£o)
- [Instala√ß√£o](#instala√ß√£o)
  - [Pr√©-requisitos](#pr√©-requisitos)
  - [Passos](#passos)
- [Uso](#uso)
  - [Exemplos de Perguntas](#exemplos-de-perguntas)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Depend√™ncias](#depend√™ncias)
- [Contribui√ß√£o](#contribui√ß√£o)
- [Solu√ß√£o de Problemas](#solu√ß√£o-de-problemas)
- [Autor](#autor)
- [Notas](#notas)
- [English (Quick Overview)](#english-quick-overview)

## Funcionalidades

- **An√°lise Explorat√≥ria de Dados (EDA)**: Responde perguntas sobre tipos de dados, distribui√ß√µes, intervalos, tend√™ncias centrais, variabilidade, padr√µes, valores frequentes, clusters, outliers e correla√ß√µes.
- **Representa√ß√µes Gr√°ficas + Sele√ß√£o de Colunas**: Gera√ß√£o autom√°tica de histogramas, boxplots, gr√°ficos de dispers√£o e outras visualiza√ß√µes, com expander para selecionar/confirmar colunas (X/Y) antes da execu√ß√£o.
- **Detec√ß√£o de Anomalias**: Identifica√ß√£o de outliers usando m√©todos como IQR e Z-score.
- **Mem√≥ria de An√°lises**: Armazena conclus√µes de an√°lises anteriores para contextualizar respostas futuras.
- **Orquestra√ß√£o Multi-Agente**: Equipe de agentes especializados (Orchestrator, Team Leader, Data Architect, Data Analyst T√©cnico, Data Analyst de Neg√≥cios, Data Scientist) trabalhando em conjunto.
- **Interface Intuitiva**: UI em Streamlit com chat interativo, upload de arquivos e exibi√ß√£o de resultados em tempo real.
- **Upload Multi-Formato**: Suporte a `CSV`, `XLSX`, `XLS` (legacy), `ODS` e `ODT` (tabelas extra√≠das como DataFrames).
- **Normaliza√ß√£o de Colunas**: Op√ß√£o para normalizar nomes para `snake_case` ASCII (remove acentos e espa√ßos), evitando erros em opera√ß√µes de jun√ß√£o e gr√°ficos.
- **Sele√ß√£o de DataFrame Padr√£o**: Escolha qual dataset servir√° de base para as an√°lises e preenchimento autom√°tico de par√¢metros das ferramentas.
- **Relacionamento entre Datasets**: UI para informar se os datasets s√£o correlacionados e definir chaves de jun√ß√£o (iguais ou diferentes) e tipo de jun√ß√£o.
- **Teste de Jun√ß√£o**: Bot√£o "Testar Jun√ß√£o" que pr√©-visualiza o resultado da uni√£o antes da execu√ß√£o do plano.
- **Pr√©via de Dataset**: Exibi√ß√£o do cabe√ßalho, amostra (4 linhas), tipos de dados e colunas candidatas a chaves (unicidade > 0.9).
- **Mem√≥ria Completa**: Armazena a resposta final completa de cada an√°lise na mem√≥ria da sess√£o (sem truncamento).
- **Relat√≥rio em PDF (ABNT + Pir√¢mide de Minto)**: Gera√ß√£o e download de relat√≥rio com capa, resumo executivo, desenvolvimento, resultados (figuras) e conclus√µes.
- **Gr√°ficos em Mem√≥ria + Download**: Renderiza√ß√£o de gr√°ficos via bytes (sem depender de arquivos no disco) e bot√£o de download por gr√°fico.
- **Manuten√ß√£o**: Bot√£o na sidebar para limpar arquivos antigos `plot_*.png` do diret√≥rio.
- **Valida√ß√£o e Auto-corre√ß√£o**: Valida√ß√£o Pydantic do Briefing e do Plano; em caso de erro de schema/JSON, ativa ciclo de auto-corre√ß√£o com feedback ao LLM.
- **Retry Seletivo + Cascata**: Tarefas que falham s√£o replanejadas e reexecutadas uma vez; dependentes j√° conclu√≠das s√£o invalidadas e reprocessadas quando necess√°rio.
- **Revis√£o Cr√≠tica (QA)**: Ap√≥s a s√≠ntese, um agente revisor (QA) aponta melhorias e limita√ß√µes; a revis√£o √© usada como contexto na resposta final.
- **Cache de Planos de Sucesso**: Planos sem erros s√£o salvos em cache (por inten√ß√£o/colunas) e podem ser reutilizados para acelerar execu√ß√µes futuras.
- **Analytics da Execu√ß√£o**: Expander com m√©tricas por ferramenta (taxa de erro/sucesso, tempo m√©dio) e inputs mais frequentes em erros.
- **Log JSON Opcional**: Toggle para salvar o `execution_log` em `logs/execution_log_<timestamp>.json`.

## Arquitetura

O sistema √© baseado em uma arquitetura modular com os seguintes componentes:

### Agentes
- **OrchestratorAgent**: Traduz perguntas do usu√°rio em briefings estruturados.
- **TeamLeaderAgent**: Cria planos de execu√ß√£o passo a passo baseados em briefings.
- **DataArchitectAgent**: Limpa e junta datasets.
- **DataAnalystTechnicalAgent**: Realiza an√°lises estat√≠sticas e EDA profundas.
- **DataAnalystBusinessAgent**: Gera gr√°ficos e insights de neg√≥cio.
- **DataScientistAgent**: Aplica machine learning para clusters e previs√µes.
- **QualityAssuranceAgent (QA Reviewer)**: Revisor cr√≠tico que avalia o rascunho t√©cnico e aponta melhorias, limita√ß√µes e poss√≠veis vieses. Suas observa√ß√µes s√£o incorporadas ao contexto da resposta final.

### Ferramentas
- **Ferramentas de Engenharia**: `join_datasets`, `join_datasets_on`, `clean_data`.
- **Ferramentas de EDA**: `descriptive_stats`, `detect_outliers`, `correlation_matrix`, `get_exploratory_analysis`.
- **Ferramentas de Visualiza√ß√£o**: `plot_histogram`, `plot_boxplot`, `plot_scatter`, `generate_chart`.
- **Ferramentas de ML**: `run_kmeans_clustering`.
- **Utilit√°rios de Dados**: `read_odt_tables` (extrai tabelas de ODT) e `normalize_dataframe_columns` (padroniza nomes de colunas).

## Documenta√ß√£o

- Guia de arquitetura e decis√µes de projeto: [ARCHITECTURE.md](./ARCHITECTURE.md)
- Diagrama de Estrutura (EN): [docs/structure.md](./docs/structure.md)
- Diagrama de Processamento (EN): [docs/data_processing.md](./docs/data_processing.md)
- Diagrama de Relacionamentos (EN): [docs/relationships.md](./docs/relationships.md)
- Guia de Opera√ß√µes/Implanta√ß√£o: [docs/OPERATIONS.md](./docs/OPERATIONS.md)
- Guia de Analytics e Logs: [docs/ANALYTICS.md](./docs/ANALYTICS.md)
- Guia do Cache de Planos: [docs/CACHE.md](./docs/CACHE.md)
- Estrat√©gia de Testes: [docs/TESTING.md](./docs/TESTING.md)
- Troubleshooting: [docs/TROUBLESHOOTING.md](./docs/TROUBLESHOOTING.md)
- Como contribuir: [CONTRIBUTING.md](./CONTRIBUTING.md)
- C√≥digo de Conduta: [CODE_OF_CONDUCT.md](./CODE_OF_CONDUCT.md)
- Changelog: [CHANGELOG.md](./CHANGELOG.md)
- Seguran√ßa: [docs/SECURITY.md](./docs/SECURITY.md)

### Pipeline de Execu√ß√£o
1. **Briefing**: Orchestrator analisa a pergunta e retorna JSON validado (Pydantic) ou aciona auto-corre√ß√£o.
2. **Plano**: Team Leader cria um plano (validado via Pydantic); em falhas, um ciclo de corre√ß√£o √© aplicado.
3. **Execu√ß√£o**: Agentes executam tarefas em ordem/respeito a depend√™ncias; em erro, retry seletivo com plano corrigido e reexecu√ß√£o em cascata dos dependentes.
4. **S√≠ntese**: Team Leader sintetiza resultados a partir de um contexto compacto.
5. **Revis√£o (QA)**: Revisor cr√≠tico gera sugest√µes; revis√£o √© incorporada ao contexto.
6. **Resposta Final**: Data Analyst de Neg√≥cios gera resposta final incorporando QA.
7. **Exporta√ß√£o**: Gera√ß√£o do relat√≥rio em PDF para download.

### Diagramas

#### Diagrama de Estrutura do Projeto
```mermaid
graph TD
    A[app.py - Interface Web Streamlit] --> B[agents.py - Defini√ß√µes dos Agentes]
    A --> C[tools.py - Ferramentas Especializadas]
    A --> D[prompts.py - Templates de Prompt]
    A --> E[config.py - Configura√ß√£o de LLM]

    B --> F[OrchestratorAgent - Traduz perguntas em briefings]
    B --> G[TeamLeaderAgent - Cria planos de execu√ß√£o]
    B --> H[DataArchitectAgent - Limpa e junta datasets]
    B --> I[DataAnalystTechnicalAgent - An√°lises estat√≠sticas]
    B --> J[DataAnalystBusinessAgent - Gera gr√°ficos e insights]
    B --> K[DataScientistAgent - Machine learning]

    C --> L[Ferramentas de Engenharia: join_datasets, clean_data]
    C --> M[Ferramentas de EDA: descriptive_stats, detect_outliers]
    C --> N[Ferramentas de Visualiza√ß√£o: plot_histogram, generate_chart]
    C --> O[Ferramentas de ML: run_kmeans_clustering]
    C --> P[Utilit√°rios: read_odt_tables, normalize_dataframe_columns]

    D --> Q[Templates para briefing, plano, s√≠ntese e QA]

    E --> R[Integra√ß√£o com LLMs: Groq, OpenAI, Gemini]

    S[config.json - Arquivo de configura√ß√£o] --> E
    V[plan_cache - session] --> A
    T[requirements.txt - Depend√™ncias] --> U[streamlit, pandas, langchain, etc.]
```

#### Diagrama de Processamento de Dados
```mermaid
flowchart TD
    A[Usu√°rio faz upload de datasets] --> B[Pr√©-processamento]
    B --> C[Configura√ß√£o de relacionamentos]
    C --> D[Usu√°rio pergunta]
    D --> E[OrchestratorAgent: Briefing em JSON]
    E --> F[TeamLeaderAgent: Plano de execu√ß√£o]
    F --> G[Normaliza√ß√£o do plano em app.py]
    G --> H[Expander: Sele√ß√£o de colunas]
    H --> I[Execu√ß√£o: Agentes chamam ferramentas]
    I --> J[Resultados no shared_context]
    J --> K[TeamLeader sintetiza resultados]
    K --> L[Revis√£o Cr√≠tica]
    L --> M[DataAnalystBusinessAgent: Resposta final]
    M --> N[Resposta armazenada na mem√≥ria]
    N --> O[Gr√°ficos em mem√≥ria + download]
    O --> P[PDF: ABNT + Pir√¢mide de Minto]
    P --> Q[Analytics: taxa por ferramenta]
    Q --> R[Logs: opcional salvar JSON]
    R --> S[Fim do processamento]
```

#### Diagrama de Relacionamentos entre Agentes e Ferramentas
```mermaid
flowchart TD
    subgraph "Agentes de Orquestra√ß√£o"
        A[OrchestratorAgent]
        B[TeamLeaderAgent]
    end

    subgraph "Agentes Especializados"
        C[DataArchitectAgent]
        D[DataAnalystTechnicalAgent]
        E[DataAnalystBusinessAgent]
        F[DataScientistAgent]
    end

    subgraph "Ferramentas de Engenharia"
        G[join_datasets]
        H[clean_data]
        I[normalize_dataframe_columns]
    end

    subgraph "Ferramentas de EDA"
        J[descriptive_stats]
        K[detect_outliers]
        L[correlation_matrix]
        M[get_exploratory_analysis]
    end

    subgraph "Ferramentas de Visualiza√ß√£o"
        N[plot_histogram]
        O[plot_boxplot]
        P[plot_scatter]
        Q[generate_chart]
    end

    subgraph "Ferramentas de ML"
        R[run_kmeans_clustering]
    end

    subgraph "Utilit√°rios"
        S[read_odt_tables]
    end

    A --> B
    B --> C
    B --> D
    B --> E
    B --> F

    C --> G
    C --> H
    C --> I

    D --> J
    D --> K
    D --> L
    D --> M

    E --> N
    E --> O
    E --> P
    E --> Q

    F --> R

    C --> S
    D --> S
    E --> S
    F --> S

    T[app.py - Interface e Execu√ß√£o] --> A
    T --> B
    T --> C
    T --> D
    T --> E
    T --> F

    U[tools.py - Biblioteca de Ferramentas] --> G
    U --> H
    U --> I
    U --> J
    U --> K
    U --> L
    U --> M
    U --> N
    U --> O
    U --> P
    U --> Q
    U --> R
    U --> S
```

### Pr√©-requisitos
- Python 3.8+
- Conta em provedor de LLM (Groq, OpenAI ou Google Gemini) com chave de API.

### Passos
1. Clone o reposit√≥rio:
   ```bash
   git clone https://github.com/Benrebello/Autonomous_Data_Consulting
   cd Autonomous_Data_consulting
   ```

2. Instale as depend√™ncias:
   ```bash
   pip install -r requirements.txt
   ```

   Observa√ß√£o: o suporte a `.xls` (Excel legado) requer `xlrd`, j√° inclu√≠do no `requirements.txt`. O PDF usa `reportlab` (tamb√©m inclu√≠do).

3. Configure o LLM em `config.json`:
   ```json
   {
     "provider": "groq",
     "model": "llama-3.1-8b-instant",
     "api_key": "sua-chave-aqui"
   }
   ```

4. Execute a aplica√ß√£o:
   ```bash
   streamlit run app.py
   ```

## Uso

1. Abra a aplica√ß√£o no navegador.
2. Fa√ßa upload de um ou mais arquivos (`CSV`, `XLSX`, `XLS`, `ODS`, `ODT`).
3. Na sidebar:
   - Ative "Normalizar nomes de colunas (snake_case)" (recomendado).
   - Selecione o **DataFrame padr√£o**.
   - Se houver 2+ datasets, marque se **s√£o relacionados** e defina as **chaves** (iguais ou diferentes) e o **tipo de jun√ß√£o**.
   - Opcionalmente, clique em **Testar Jun√ß√£o** para ver uma pr√©via.
4. Abra o expansor de **Pr√©via do DataFrame** para ver cabe√ßalho, 4 linhas de amostra, tipos e candidatas a chaves.
5. Digite sua pergunta no chat, por exemplo: "Fa√ßa uma EDA completa do dataset" ou "Quais s√£o os outliers na coluna 'pre√ßo'?".
6. Visualize o plano, o progresso das tarefas, gr√°ficos e a resposta final com conclus√µes.
7. Fa√ßa o download do relat√≥rio em PDF (ABNT + Pir√¢mide de Minto) pelo bot√£o exibido ap√≥s a resposta.

---

## English (Quick Overview)

This project is a Streamlit-based autonomous multi-agent app for EDA (Exploratory Data Analysis). Upload datasets (CSV, XLSX, XLS, ODS, ODT tables), configure joins, and chat with a team of AI agents to get insights, charts, and a final report.

### Key Features
- Multi-agent orchestration (Orchestrator, Team Leader, Data Architect, Technical/Business Analysts, Data Scientist).
- File uploads: CSV, XLSX, legacy XLS, ODS, and ODT (tables extracted to DataFrames).
- Optional column normalization (snake_case ASCII) to stabilize joins and plots.
- Default DataFrame selection and join configuration UI (same/different keys, join types).
- Dataset preview (headers, 4-row sample, dtypes, key candidates by uniqueness).
- Charts rendered in-memory with per-chart download.
- PDF export (ABNT-like formatting + Minto Pyramid structure).
- Robust JSON and plan normalization to handle model variations.

### Installation
```bash
pip install -r requirements.txt
```
Notes: XLS requires `xlrd`; PDF generation uses `reportlab` (both included in requirements).

### Usage
```bash
streamlit run app.py
```
1) Upload datasets in the sidebar and (optionally) normalize column names.
2) Select the default DataFrame, configure relationships/joins, and test the join.
3) Ask your question in chat (e.g., "Run a complete EDA").
4) Review the execution plan, results, and charts; download the generated PDF report.

### Exemplos de Perguntas
- "Quais s√£o os tipos de dados das colunas?"
- "Gere um histograma para a vari√°vel 'idade'."
- "Detecte outliers na coluna 'sal√°rio' usando IQR."
- "Qual a correla√ß√£o entre 'vendas' e 'publicidade'?"
- "Fa√ßa uma an√°lise de clusters nos dados."

## Estrutura do Projeto

```
consultoria-dados-autonoma/
‚îú‚îÄ‚îÄ app.py                 # Aplica√ß√£o principal Streamlit
‚îú‚îÄ‚îÄ agents.py              # Defini√ß√µes dos agentes
‚îú‚îÄ‚îÄ tools.py               # Ferramentas especializadas
‚îú‚îÄ‚îÄ prompts.py             # Templates de prompt
‚îú‚îÄ‚îÄ config.py              # Configura√ß√£o de LLM
‚îú‚îÄ‚îÄ config.json            # Arquivo de configura√ß√£o
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias
‚îî‚îÄ‚îÄ README.md              # Este arquivo
```

## Depend√™ncias

- streamlit: Interface web
- pandas: Manipula√ß√£o de dados
- langchain, langchain-groq, langchain-openai, langchain-google-genai: Integra√ß√£o com LLMs
- matplotlib, seaborn: Visualiza√ß√µes
- scikit-learn: Machine learning (clusters, outliers)
- openpyxl, odfpy, xlrd: Suporte a Excel/ODS/Excel legado
- reportlab: Gera√ß√£o de relat√≥rio em PDF
- python-dotenv: Vari√°veis de ambiente
- pydantic: Modelagem de dados

## Contribui√ß√£o

1. Fork o projeto.
2. Crie uma branch para sua feature (`git checkout -b feature/nova-ferramenta`).
3. Commit suas mudan√ßas (`git commit -m 'Adiciona nova ferramenta'`).
4. Push para a branch (`git push origin feature/nova-ferramenta`).
5. Abra um Pull Request.

## Solu√ß√£o de Problemas

- **Chave de API ou modelo indispon√≠vel**
  - Verifique se a chave foi inserida corretamente na sidebar ou no `config.json`.
  - Caso veja erro de modelo descontinuado (ex.: `model_decommissioned`), troque para `llama-3.1-8b-instant` no `config.json` ou na UI.

- **Erro ao ler arquivos Excel/ODS/ODT**
  - `XLSX`: requer `openpyxl` (j√° incluso).
  - `XLS` (legado): requer `xlrd` (j√° incluso). Se faltar, instale: `pip install xlrd`.
  - `ODS`: requer `odfpy` (j√° incluso). Se faltar, instale: `pip install odfpy`.
  - `ODT`: somente documentos com tabelas s√£o suportados. Cada tabela √© convertida em um DataFrame. Se n√£o houver tabelas, um aviso ser√° exibido.

- **Nomes de colunas com acentos/espa√ßos**
  - Ative na sidebar a op√ß√£o "Normalizar nomes de colunas (snake_case)" para evitar erros em joins e gr√°ficos.

- **Jun√ß√µes com poucos resultados ou colunas duplicadas**
  - Use o painel "Os datasets s√£o relacionados?" para escolher chaves adequadas e o tipo de jun√ß√£o (`inner/left/right/outer`).
  - Use o bot√£o "Testar Jun√ß√£o" para visualizar a uni√£o antes de executar o plano e conferir colunas duplicadas (`_x`, `_y`).

- **Plano em JSON fora do schema (sem `execution_plan`)**
  - Os prompts foram endurecidos para JSON estrito e o app normaliza automaticamente varia√ß√µes (ex.: `tarefas`, `plano_de_execucao`, `projeto`). Se ainda falhar, um plano m√≠nimo √© gerado para manter o fluxo.

- **Erros de limite de tokens (TPM) em Groq / 413**
  - O contexto enviado para s√≠ntese √© compactado (amostras pequenas, truncamento de strings). Se necess√°rio, troque para um modelo mais leve (ex.: `llama-3.1-8b-instant`) e reduza datasets muito grandes.

- **Gr√°ficos n√£o aparecem**
  - Verifique se existem colunas num√©ricas. O sistema seleciona a primeira coluna num√©rica por padr√£o para histogramas/boxplots.
  - Gr√°ficos agora s√£o renderizados a partir de bytes em mem√≥ria; cada gr√°fico inclui bot√£o de download. H√° um bot√£o de manuten√ß√£o para remover `plot_*.png` antigos.

- **Erros de JSON devolvidos pelo LLM**
  - As respostas s√£o limpas de blocos markdown e validadas. Se o erro persistir, revise o prompt ou tente novamente; a aplica√ß√£o exibir√° mensagens claras do conte√∫do inv√°lido.

- **Streaming do texto fragmentado no chat**
  - A aplica√ß√£o agrega os chunks e apresenta uma √∫nica mensagem fluida. Se notar quebras estranhas, recarregue a p√°gina para reiniciar o estado.

## Autor

Desenvolvido por [Seu Nome] como parte do desafio individual do curso I2A2.

## Notas

- O sistema usa mem√≥ria baseada em session state para armazenar conclus√µes de an√°lises anteriores.
- Para provedores de LLM, certifique-se de que a chave de API tem permiss√µes adequadas.
- Em caso de erros, verifique os logs do Streamlit e os arquivos de configura√ß√£o.
- ODT: apenas documentos com **tabelas** s√£o suportados (cada tabela √© convertida em um DataFrame).

---

## Full README in English

# Autonomous Data Consulting

A web application based on autonomous AI agents for exploratory data analysis (EDA). It allows users to upload CSV files and converse with a team of specialized agents to extract insights, generate graphs, and obtain actionable conclusions about the data.

## Table of Contents

- [Features](#features)
- [Architecture](#architecture)
  - [Tools](#tools)
  - [Documentation](#documentation)
  - [Execution Pipeline](#execution-pipeline)
  - [Diagrams](#diagrams)
- [Installation](#installation)
  - [Prerequisites](#prerequisites)
  - [Steps](#steps)
- [Usage](#usage)
  - [Example Questions](#example-questions)
- [Project Structure](#project-structure)
- [Dependencies](#dependencies)
- [Contribution](#contribution)
- [Troubleshooting](#troubleshooting)
- [Author](#author)
- [Notes](#notes)

## Features

- **Exploratory Data Analysis (EDA)**: Answers questions about data types, distributions, ranges, central tendencies, variability, patterns, frequent values, clusters, outliers, and correlations.
- **Graphical Representations**: Automatic generation of histograms, boxplots, scatter plots, and other visualizations.
- **Anomaly Detection**: Identification of outliers using methods like IQR and Z-score.
- **Analysis Memory**: Stores conclusions from previous analyses to contextualize future responses.
- **Multi-Agent Orchestration**: Team of specialized agents (Orchestrator, Team Leader, Data Architect, Technical Data Analyst, Business Data Analyst, Data Scientist) working together.
- **Intuitive Interface**: Streamlit UI with interactive chat, file uploads, and real-time result display.
- **Multi-Format Upload**: Support for `CSV`, `XLSX`, `XLS` (legacy), `ODS`, and `ODT` (tables extracted as DataFrames).
- **Column Name Normalization**: Option to normalize names to `snake_case` ASCII (removes accents and spaces), avoiding errors in join operations and graphs.
- **Default DataFrame Selection**: Choose which dataset will serve as the base for analyses and automatic parameter filling for tools.
- **Dataset Relationships**: UI to inform if datasets are correlated and define join keys (same or different) and join type.
- **Join Testing**: "Test Join" button that previews the union result before plan execution.
- **Dataset Preview**: Display of header, 4-row sample, data types, and candidate key columns (uniqueness > 0.9).
- **Complete Memory**: Stores the full final answer of each analysis in session memory (without truncation).
- **PDF Report (ABNT + Minto Pyramid)**: Generation and download of report with cover, executive summary, development, results (figures), and conclusions.
- **In-Memory Charts + Download**: Rendering of charts via bytes (without relying on disk files) and per-chart download button.
- **Maintenance**: Button in sidebar to clean old `plot_*.png` files from directory.
- **Plan and JSON Resilience**: Prompts adjusted to force strict JSON output and robust plan normalization for variations outside schema.

## Architecture

The system is based on a modular architecture with the following components:

### Agents
- **OrchestratorAgent**: Translates user questions into structured briefings.
- **TeamLeaderAgent**: Creates step-by-step execution plans based on briefings.
- **DataArchitectAgent**: Cleans and joins datasets.
- **DataAnalystTechnicalAgent**: Performs statistical and deep EDA analyses.
- **DataAnalystBusinessAgent**: Generates graphs and business insights.
- **DataScientistAgent**: Applies machine learning for clusters and predictions.
- **QualityAssuranceAgent (QA Reviewer)**: Critical reviewer that inspects the technical draft, highlights limitations and communication improvements, and its notes are fed into the final response context.

### Tools
- **Engineering Tools**: `join_datasets`, `join_datasets_on`, `clean_data`.
- **EDA Tools**: `descriptive_stats`, `detect_outliers`, `correlation_matrix`, `get_exploratory_analysis`.
- **Visualization Tools**: `plot_histogram`, `plot_boxplot`, `plot_scatter`, `generate_chart`.
- **ML Tools**: `run_kmeans_clustering`.
- **Data Utilities**: `read_odt_tables` (extracts tables from ODT) and `normalize_dataframe_columns` (standardizes column names).

### Documentation

- Architecture and project decision guide: [ARCHITECTURE.md](./ARCHITECTURE.md)

### Execution Pipeline
1. **Briefing**: Orchestrator analyzes the question.
2. **Plan**: Team Leader creates a plan with dependent tasks.
3. **Execution**: Agents execute tasks in order, resolving dependencies.
4. **Synthesis**: Team Leader synthesizes results.
5. **Final Response**: Business Data Analyst generates response with conclusions and memory.
6. **Export**: PDF report generation for download.

### Diagrams

#### Project Structure Diagram
```mermaid
graph TD
    A[app.py - Streamlit Web Interface] --> B[agents.py - Agent Definitions]
    A --> C[tools.py - Specialized Tools]
    A --> D[prompts.py - Prompt Templates]
    A --> E[config.py - LLM Configuration]

    B --> F[OrchestratorAgent - Translates questions into briefings]
    B --> G[TeamLeaderAgent - Creates execution plans]
    B --> H[DataArchitectAgent - Cleans and joins datasets]
    B --> I[DataAnalystTechnicalAgent - Statistical analyses]
    B --> J[DataAnalystBusinessAgent - Generates graphs and insights]
    B --> K[DataScientistAgent - Machine learning]

    C --> L[Engineering Tools: join_datasets, clean_data]
    C --> M[EDA Tools: descriptive_stats, detect_outliers]
    C --> N[Visualization Tools: plot_histogram, generate_chart]
    C --> O[ML Tools: run_kmeans_clustering]
    C --> P[Utilities: read_odt_tables, normalize_dataframe_columns]

    D --> Q[Templates for briefing, plan, synthesis and QA]

    E --> R[LLM Integration: Groq, OpenAI, Gemini]

    S[config.json - Configuration file] --> E
    T[requirements.txt - Dependencies] --> U[streamlit, pandas, langchain, etc.]
    V[plan_cache - session] --> A
```

#### Data Processing Diagram
```mermaid
flowchart TD
    A[User uploads datasets] --> B[Preprocessing]
    B --> C[Relationship and join configuration]
    C --> D[User asks question in chat]
    D --> E[OrchestratorAgent: Strict JSON briefing]
    E --> F[TeamLeaderAgent: Briefing plan JSON]
    F --> G[Plan normalization in app.py]
    G --> H[Expander: Column selection]
    H --> I[Execution: Agents call tools]
    I --> J[Results stored in shared_context]
    J --> K[Team Leader synthesizes results]
    K --> L[QA Review]
    L --> M[DataAnalystBusinessAgent]
    M --> N[Full response stored in session memory]
    N --> O[In-memory charts and download]
    O --> P[PDF: ABNT-like with Minto Pyramid]
    P --> Q[Analytics: success/error by tool]
    Q --> R[Logs: optional JSON save to logs]
    R --> S[End of processing]
```

#### Relationships Diagram between Agents and Tools
```mermaid
flowchart TD
    subgraph "Orchestration Agents"
        A[OrchestratorAgent]
        B[TeamLeaderAgent]
    end

    subgraph "Specialized Agents"
        C[DataArchitectAgent]
        D[DataAnalystTechnicalAgent]
        E[DataAnalystBusinessAgent]
        F[DataScientistAgent]
    end

    subgraph "Engineering Tools"
        G[join_datasets]
        H[clean_data]
        I[normalize_dataframe_columns]
    end

    subgraph "EDA Tools"
        J[descriptive_stats]
        K[detect_outliers]
        L[correlation_matrix]
        M[get_exploratory_analysis]
    end

    subgraph "Visualization Tools"
        N[plot_histogram]
        O[plot_boxplot]
        P[plot_scatter]
        Q[generate_chart]
    end

    subgraph "ML Tools"
        R[run_kmeans_clustering]
    end

    subgraph "Utilities"
        S[read_odt_tables]
    end

    A --> B
    B --> C
    B --> D
    B --> E
    B --> F

    C --> G
    C --> H
    C --> I

    D --> J
    D --> K
    D --> L
    D --> M

    E --> N
    E --> O
    E --> P
    E --> Q

    F --> R

    C --> S
    D --> S
    E --> S
    F --> S

    T[app.py - Interface and Execution] --> A
    T --> B
    T --> C
    T --> D
    T --> E
    T --> F

    U[tools.py - Tools Library] --> G
    U --> H
    U --> I
    U --> J
    U --> K
    U --> L
    U --> M
    U --> N
    U --> O
    U --> P
    U --> Q
    U --> R
    U --> S
```

